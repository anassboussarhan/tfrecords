{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anassboussarhan/tfrecords/blob/master/tfrecords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WzoB7-NjiX10",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import sys\n",
        "import threading\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from queue import Queue\n",
        "from glob import glob\n",
        "\n",
        "image_dir='/content/drive/My Drive/Projetand/train/image/'\n",
        "mask_dir='/content/drive/My Drive/Projetand/train/mask/'\n",
        "image_suffix=\".png\"\n",
        "mask_suffix=\".png\"\n",
        "train_size=1\n",
        "validation_size=0\n",
        "output_dir='/content/drive/My Drive/Projetand/'\n",
        "shards=1\n",
        "threads=1\n",
        "shuffle=False\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UIjN-tpSkUNW",
        "colab_type": "code",
        "outputId": "a9ba4e44-636d-4566-9c8d-512a67a24cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8CkM_WJuY2Z-",
        "colab_type": "code",
        "outputId": "79be052f-bba3-4479-8336-8cddaf7ad68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _convert_to_example(image_buffer, mask_buffer, filename, mask_filename):\n",
        "    example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image': _bytes_feature(image_buffer),\n",
        "        'mask': _bytes_feature(mask_buffer),\n",
        "    }))\n",
        "    return example\n",
        "\n",
        "\n",
        "def _process_image_files_batch(thread_index, batch_data, shards, total_shards, mask_dir, mask_suffix, output_dir,\n",
        "                               output_name, error_queue):\n",
        "    batch_size = len(batch_data)\n",
        "    batch_per_shard = batch_size // len(shards)\n",
        "\n",
        "    counter = 0\n",
        "    error_counter = 0\n",
        "    for s in range(len(shards)):\n",
        "        shard = shards[s]\n",
        "        output_filename = '%s-%.5d-of-%.5d' % (output_name, shard, total_shards)\n",
        "        output_file = os.path.join(output_dir, output_filename)\n",
        "\n",
        "        writer = tf.python_io.TFRecordWriter(output_file)\n",
        "        shard_counter = 0\n",
        "        shard_range = (s * batch_per_shard, min(batch_per_shard, batch_size - (s * batch_per_shard)))\n",
        "        files_in_shard = np.arange(shard_range[0], shard_range[1], dtype=int)\n",
        "        for i in files_in_shard:\n",
        "            filename = data[i]\n",
        "            mask_filename = os.path.join(mask_dir,\n",
        "                                         os.path.splitext(os.path.split(filename)[-1])[0] + mask_suffix)\n",
        "            try:\n",
        "                image_buffer = tf.gfile.FastGFile(filename, 'rb').read()\n",
        "                mask_buffer = tf.gfile.FastGFile(mask_filename, 'rb').read()\n",
        "                example = _convert_to_example(image_buffer, mask_buffer, filename, mask_filename)\n",
        "                writer.write(example.SerializeToString())\n",
        "                shard_counter += 1\n",
        "                counter += 1\n",
        "            except StopIteration as e:\n",
        "                error_counter += 1\n",
        "                error_msg = repr(e)\n",
        "                error_queue.put(error_msg)\n",
        "\n",
        "        print('%s [thread %d]: Wrote %d images to %s, with %d errors.' %\n",
        "              (datetime.now(), thread_index, shard_counter, output_file, error_counter))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    print('%s [thread %d]: Wrote %d images to %d shards, with %d errors.' %\n",
        "          (datetime.now(), thread_index, counter, len(shards), error_counter))\n",
        "\n",
        "\n",
        "def create(data, mask_dir, mask_suffix, output_name, output_dir, num_shards, num_threads):\n",
        "    num_data_per_thread = len(data) // num_threads\n",
        "    num_shard_per_thread = num_shards // num_threads\n",
        "    batch_data_ranges = [(i * num_data_per_thread, min(num_data_per_thread, len(data) - i * num_data_per_thread))\n",
        "                         for i in range(num_threads)]\n",
        "\n",
        "    coord = tf.train.Coordinator()\n",
        "\n",
        "    error_queue = Queue()\n",
        "\n",
        "    threads = []\n",
        "    for thread_index in range(1, num_threads + 1):\n",
        "        batch_ranges = batch_data_ranges[thread_index - 1]\n",
        "        batch_data = data[batch_ranges[0]:batch_ranges[1]]\n",
        "        shards = [thread_index + (thread_index - 1) * (num_shard_per_thread - 1) + shard\n",
        "                  for shard in range(num_shard_per_thread)]\n",
        "        args = (thread_index, batch_data, shards, num_shards, mask_dir, mask_suffix, output_name, output_dir,\n",
        "                error_queue)\n",
        "        t = threading.Thread(target=_process_image_files_batch, args=args)\n",
        "        t.start()\n",
        "        threads.append(t)\n",
        "\n",
        "    coord.join(threads)\n",
        "\n",
        "    errors = []\n",
        "    while not error_queue.empty():\n",
        "        errors.append(error_queue.get())\n",
        "    print('%d examples failed.' % (len(errors),))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = glob(os.path.join(image_dir, \"*\" + image_suffix))\n",
        "\n",
        "\n",
        "\n",
        "num_data = len(data)\n",
        "num_train = int(round(num_data * train_size))\n",
        "num_validation = round(num_data * validation_size)\n",
        "\n",
        "training = data[1:num_train]\n",
        "create(training, mask_dir, mask_suffix, output_dir, \"train\", shards, threads)\n",
        "if validation_size > 0:\n",
        "    validation = data[num_train:num_train + num_validation]\n",
        "    create(validation, mask_dir, mask_suffix, output_dir, \"val\", shards, threads)\n",
        "if train_size + validation_size < 1:\n",
        "    test = data[num_train + num_validation:]\n",
        "    create(test, mask_dir, mask_suffix, output_dir, \"test\", shards, threads)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-10-13 01:40:22.724733 [thread 1]: Wrote 26 images to /content/drive/My Drive/Projetand/train-00001-of-00001, with 0 errors.\n",
            "2018-10-13 01:40:22.726194 [thread 1]: Wrote 26 images to 1 shards, with 0 errors.\n",
            "0 examples failed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o_oLRau_p-PT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}